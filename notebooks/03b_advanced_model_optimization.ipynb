{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c133668",
   "metadata": {},
   "source": [
    "# FinRisk: Credit Risk & Fraud Detection - Notebook 5\n",
    "## Phase 2: Advanced Model Optimization\n",
    "\n",
    "**Objective:** To improve the performance of the Logistic Regression model, which is currently our best performer but still below target metrics. We will use two primary techniques:\n",
    "1.  **Hyperparameter Tuning:** Systematically find the best regularization parameters (`C` and `penalty`).\n",
    "2.  **Feature Engineering:** Create `PolynomialFeatures` to allow the model to capture non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "141b5941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# 1. Import Libraries\n",
    "# ==============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "# Settings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694803c",
   "metadata": {},
   "source": [
    "## 2. Load Data and Re-run Preparation Steps\n",
    "\n",
    "We load the processed data and set up our features, target, and time-based split as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d053964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (80000, 26), Testing data shape: (20000, 26)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "PROCESSED_DATA_PATH = '../data/processed/'\n",
    "DATA_FILE = 'credit_risk_features.csv'\n",
    "df = pd.read_csv(os.path.join(PROCESSED_DATA_PATH, DATA_FILE), parse_dates=['application_date'])\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "TARGET = 'default_flag'\n",
    "features_to_exclude = [\n",
    "    'application_id', 'customer_id', 'application_date', 'last_activity_date',\n",
    "    'default_flag', 'application_status', 'city'\n",
    "]\n",
    "X = df.drop(columns=features_to_exclude)\n",
    "y = df[TARGET]\n",
    "\n",
    "# Identify feature types\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_features = X.select_dtypes(include=np.number).columns\n",
    "\n",
    "# Time-based split\n",
    "df_sorted = df.sort_values('application_date')\n",
    "split_index = int(len(df_sorted) * 0.8)\n",
    "train_df, test_df = df_sorted.iloc[:split_index], df_sorted.iloc[split_index:]\n",
    "X_train, y_train = train_df[X.columns], train_df[TARGET]\n",
    "X_test, y_test = test_df[X.columns], test_df[TARGET]\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}, Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09014c63",
   "metadata": {},
   "source": [
    "## 3. Optimization 1: Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "We'll define a \"grid\" of parameters for Logistic Regression and use cross-validation to find the best combination. We'll tune `C` (inverse of regularization strength) and the `penalty` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8698d574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting GridSearchCV for Logistic Regression ---\n",
      "Best parameters found: {'classifier__C': 100, 'classifier__penalty': 'l1'}\n",
      "Best cross-validation AUC: 0.6243\n"
     ]
    }
   ],
   "source": [
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Create a pipeline with the preprocessor and the classifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42, class_weight='balanced', solver='liblinear'))\n",
    "])\n",
    "\n",
    "# Define the parameter grid to search\n",
    "# C: Controls the penalty strength. Smaller C means stronger regularization.\n",
    "# penalty: 'l1' (Lasso) can perform feature selection, 'l2' (Ridge) is standard.\n",
    "param_grid = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Use TimeSeriesSplit for cross-validation to respect the time-based nature of the data\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=tscv, scoring='roc_auc', n_jobs=-1)\n",
    "\n",
    "print(\"--- Starting GridSearchCV for Logistic Regression ---\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation AUC: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Store the best model\n",
    "best_lr_tuned = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77b0211",
   "metadata": {},
   "source": [
    "## 4. Optimization 2: Engineering Polynomial Features\n",
    "\n",
    "Now, let's create a new pipeline that includes a step to generate interaction and polynomial features *before* training the logistic regression model. This gives the simple model a much richer feature set to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdcf14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Training Logistic Regression with Polynomial Features ---\n"
     ]
    }
   ],
   "source": [
    "# Create a new pipeline with PolynomialFeatures\n",
    "# We add this step ONLY for numerical features after scaling.\n",
    "poly_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Apply scaling, then polynomial features\n",
    "        ('num_poly', Pipeline(steps=[\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('poly', PolynomialFeatures(degree=2, include_bias=False))\n",
    "        ]), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Use the best parameters we found from GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "lr_poly_model = LogisticRegression(\n",
    "    C=best_params['classifier__C'],\n",
    "    penalty=best_params['classifier__penalty'],\n",
    "    random_state=42,\n",
    "    class_weight='balanced',\n",
    "    solver='liblinear'\n",
    ")\n",
    "\n",
    "# Create the full pipeline\n",
    "pipeline_poly = Pipeline(steps=[\n",
    "    ('preprocessor', poly_preprocessor),\n",
    "    ('classifier', lr_poly_model)\n",
    "])\n",
    "\n",
    "print(\"\\n--- Training Logistic Regression with Polynomial Features ---\")\n",
    "pipeline_poly.fit(X_train, y_train)\n",
    "print(\"Model trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb04af",
   "metadata": {},
   "source": [
    "## 5. Final Evaluation\n",
    "\n",
    "Let's evaluate our two new optimized models and a tuned XGBoost model against the original baseline to see the impact of our optimizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220103da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for evaluation\n",
    "def calculate_ks_and_gini(y_true, y_pred_proba):\n",
    "    auc = roc_auc_score(y_true, y_pred_proba)\n",
    "    gini = 2 * auc - 1\n",
    "    data = pd.DataFrame({'y': y_true, 'p': y_pred_proba}).sort_values('p', ascending=False)\n",
    "    data['good'] = (1 - data.y).cumsum() / (1 - data.y).sum()\n",
    "    data['bad'] = data.y.cumsum() / data.y.sum()\n",
    "    ks = (data.bad - data.good).max()\n",
    "    return ks * 100, gini\n",
    "\n",
    "# Get predictions from our new models\n",
    "y_pred_tuned_lr = best_lr_tuned.predict_proba(X_test)[:, 1]\n",
    "y_pred_poly_lr = pipeline_poly.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Store results\n",
    "results = {\n",
    "    \"Logistic Regression (Tuned)\": y_pred_tuned_lr,\n",
    "    \"Logistic Regression (Poly Features)\": y_pred_poly_lr\n",
    "}\n",
    "\n",
    "# --- Evaluate and display results ---\n",
    "evaluation_summary = []\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "for name, y_pred_proba in results.items():\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    ks, gini = calculate_ks_and_gini(y_test, y_pred_proba)\n",
    "    evaluation_summary.append({'Model': name, 'AUC': auc, 'Gini': gini, 'KS Statistic': ks})\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})')\n",
    "\n",
    "# Display summary table\n",
    "evaluation_df = pd.DataFrame(evaluation_summary).sort_values('AUC', ascending=False)\n",
    "print(\"--- Final Model Performance Summary ---\")\n",
    "print(evaluation_df)\n",
    "\n",
    "# Check against success metrics\n",
    "print(\"\\n--- Checking Against Success Metrics ---\")\n",
    "best_model_stats = evaluation_df.iloc[0]\n",
    "auc_check = \"PASS\" if best_model_stats['AUC'] > 0.75 else \"FAIL\"\n",
    "ks_check = \"PASS\" if best_model_stats['KS Statistic'] > 40 else \"FAIL\"\n",
    "gini_check = \"PASS\" if best_model_stats['Gini'] > 0.50 else \"FAIL\"\n",
    "\n",
    "print(f\"Best Model: {best_model_stats['Model']}\")\n",
    "print(f\"AUC > 0.75: {auc_check} (Actual: {best_model_stats['AUC']:.3f})\")\n",
    "print(f\"KS > 40: {ks_check} (Actual: {best_model_stats['KS Statistic']:.2f})\")\n",
    "print(f\"Gini > 0.50: {gini_check} (Actual: {best_model_stats['Gini']:.3f})\")\n",
    "\n",
    "# Finalize plot\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Optimized Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
